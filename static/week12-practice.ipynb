{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 12\n",
    "\n",
    "In this notebook we'll look at language models and using PyDelphin for semantic analysis.\n",
    "\n",
    "Follow along at: https://www.nltk.org/api/nltk.lm.html#module-nltk.lm"
   ]
  },
  {
   "source": [
    "# N-gram language models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Prepare Data\n",
    "\n",
    "Get sentences, add padding, get n-grams. Do this for the "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4623"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "news = brown.sents(categories='news')\n",
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('<s>',),\n",
       " ('The',),\n",
       " ('Fulton',),\n",
       " ('County',),\n",
       " ('Grand',),\n",
       " ('Jury',),\n",
       " ('said',),\n",
       " ('Friday',),\n",
       " ('an',),\n",
       " ('investigation',),\n",
       " ('of',),\n",
       " (\"Atlanta's\",),\n",
       " ('recent',),\n",
       " ('primary',),\n",
       " ('election',),\n",
       " ('produced',),\n",
       " ('``',),\n",
       " ('no',),\n",
       " ('evidence',),\n",
       " (\"''\",),\n",
       " ('that',),\n",
       " ('any',),\n",
       " ('irregularities',),\n",
       " ('took',),\n",
       " ('place',),\n",
       " ('.',),\n",
       " ('</s>',),\n",
       " ('<s>', 'The'),\n",
       " ('The', 'Fulton'),\n",
       " ('Fulton', 'County'),\n",
       " ('County', 'Grand'),\n",
       " ('Grand', 'Jury'),\n",
       " ('Jury', 'said'),\n",
       " ('said', 'Friday'),\n",
       " ('Friday', 'an'),\n",
       " ('an', 'investigation'),\n",
       " ('investigation', 'of'),\n",
       " ('of', \"Atlanta's\"),\n",
       " (\"Atlanta's\", 'recent'),\n",
       " ('recent', 'primary'),\n",
       " ('primary', 'election'),\n",
       " ('election', 'produced'),\n",
       " ('produced', '``'),\n",
       " ('``', 'no'),\n",
       " ('no', 'evidence'),\n",
       " ('evidence', \"''\"),\n",
       " (\"''\", 'that'),\n",
       " ('that', 'any'),\n",
       " ('any', 'irregularities'),\n",
       " ('irregularities', 'took'),\n",
       " ('took', 'place'),\n",
       " ('place', '.'),\n",
       " ('.', '</s>')]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.util import everygrams\n",
    "padded = list(pad_both_ends(news[0], n=2))\n",
    "list(everygrams(padded, max_len=2))\n",
    "#list(nltk.ngrams(padded, n=1)) + list(nltk.bigrams(padded))\n",
    "\n",
    "#list(nltk.bigrams(news[0], pad_left=True, pad_right=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "train, vocab = padded_everygram_pipeline(2, news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "lm = MLE(2)\n",
    "lm.fit(train, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14397"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "len(lm.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('Fulton', '<UNK>')"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "lm.vocab.lookup(['Fulton', 'fulton'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "806"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "lm.counts['The']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "lm.counts[['The']]['Fulton']"
   ]
  },
  {
   "source": [
    "## Train \n",
    "\n",
    "Train (\"fit\") the model to a bunch of text from the NLTK corpora (e.g., all/most of Brown or Reuters)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Use the model to score sentences\n",
    "\n",
    "How well does the model score sentences in the same domain? How about other domains, such as a Gutenberg book?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4.762358770834322"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "lm.entropy(nltk.bigrams(news[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "27.140187277828197"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "lm.perplexity(nltk.bigrams(news[0]))"
   ]
  },
  {
   "source": [
    "## Use the model to predict next words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# PyDelphin"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Install PyDelphin like this: `pip install pydelphin[web]`\n",
    "\n",
    "Now use it to parse a sentence using the English Resource Grammar (through `delphin.web.client`). Documentation is available at: https://pydelphin.readthedocs.io"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphin.web import client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.parse('The dog chased the cat.', params={'mrs': 'json'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = response.result(0).mrs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<EP object (h4:_the_q(ARG0 x6, RSTR h7, BODY h5)) at 139753161129024>,\n",
       " <EP object (h8:_dog_n_1(ARG0 x6)) at 139753160424416>,\n",
       " <EP object (h2:_chase_v_1(ARG0 e3, ARG1 x6, ARG2 x9)) at 139753160424512>,\n",
       " <EP object (h10:_the_q(ARG0 x9, RSTR h12, BODY h11)) at 139753160424608>,\n",
       " <EP object (h13:_cat_n_1(ARG0 x9)) at 139753160424704>]"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "m.rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<DMRS object (_the_q _dog_n_1 _chase_v_1 _the_q _cat_n_1) at 139753150859488>"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "from delphin import dmrs\n",
    "d = dmrs.from_mrs(m)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ TOP: h1\n  INDEX: e3 [ e SF: prop TENSE: past MOOD: indicative PROG: - PERF: - ]\n  RELS: < [ _the_q<0:3> LBL: h4 ARG0: x6 [ x PERS: 3 NUM: sg IND: + ] RSTR: h7 BODY: h5 ]\n          [ _dog_n_1<4:7> LBL: h8 ARG0: x6 ]\n          [ _chase_v_1<8:14> LBL: h2 ARG0: e3 ARG1: x6 ARG2: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _the_q<15:18> LBL: h10 ARG0: x9 RSTR: h12 BODY: h11 ]\n          [ _cat_n_1<19:23> LBL: h13 ARG0: x9 ] >\n  HCONS: < h1 qeq h2 h7 qeq h8 h12 qeq h13 > ]\n"
     ]
    }
   ],
   "source": [
    "from delphin.codecs import simplemrs, simpledmrs\n",
    "print(simplemrs.encode(m, indent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dmrs {\n  [top=10002 index=10002]\n  10000 [_the_q<0:3>];\n  10001 [_dog_n_1<4:7> x PERS=3 NUM=sg IND=+];\n  10002 [_chase_v_1<8:14> e SF=prop TENSE=past MOOD=indicative PROG=- PERF=-];\n  10003 [_the_q<15:18>];\n  10004 [_cat_n_1<19:23> x PERS=3 NUM=sg IND=+];\n  10000:RSTR/H -> 10001;\n  10002:ARG1/NEQ -> 10001;\n  10002:ARG2/NEQ -> 10004;\n  10003:RSTR/H -> 10004;\n}\n"
     ]
    }
   ],
   "source": [
    "print(simpledmrs.encode(d, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "84708403546ecd1e3944b1508f8d5c894da9f0666a04f38efb485e053f6828a8"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}